#Scrip para capturar tweets da rede social Twitter

#Instalar e carregar pacotes abaixo

install.packages("dplyr")

install.packages("tidyverse")

install.packages("twitteR")

install.packages("wordcloud")

install.packages("RColorBrewer")

install.packages("tidytext")

install.packages("stringr")

install.packages("tm")

install.packages("slam")

install.packages("SnowballC")


#Carregando os pacotes

library(dplyr)
library(tidyverse)
library(twitteR)
library(wordcloud)
library(RColorBrewer)
library(tidytext)
library(stringr)
library(tm)
library(slam)
library(SnowballC)

#Por favor, usar as keys próprias fornecidas para a sua conta do Twitter

consumer_key<-"kB08foOYD9jX4vxJsGatjo9rT"
consumer_secret<-"nC84tG7NjQy44jgRn9s13ZMrxlhwR6QYfZBCIKZzOyf8M3UMrN"
access_token<-"1307777072245420035-nxjCHO1nHYHapTDVvjCB8Ibb3RRVXI"
access_secret<- "or0iSEfEKen2kI8qJV2XvC99ZEu8wr8P3mCBJifft9pIc"

#Com a função setup_twitter_oauth conseguimos conectar o R ao Twitter
  
?setup_twitter_oauth

setup_twitter_oauth(consumer_key,consumer_secret,access_token,access_secret)

#A função availableTrendsLocations busca um código de localização das principais cidades do mundo
availableTrendLocations()

#A função getTrends busca os principais assuntos do momento em uma determinada cidade com o código obtido pela função availableTrendsLocations
?getTrends

#Tendências da cidade de São Paulo
getTrends("455827")

#A função searchTwitter busca palavras específicas determinadas pela programadora

?searchTwitteR

#Procurando tweets com a palavra "pantanal" em português (BR)

pantanal = searchTwitteR("pantanal",n=100,lang="pt")

pantanal = pantanal %>% twListToDF

#Empilhando os data frames para uma base final 

pantanal_base<-rbind.data.frame(pantanal,pantanal2) 

#Baixando a base em Excel

write.csv(pantanal_base,"base_final_pantanal.csv")

#Nuvem de palavras: análise de corpus textual

#1º passo: limpeza de texto
subs = "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https"

pantanal_tokens<-pantanal %>% mutate(text=str_replace_all(text, subs,"")) %>%
  unnest_tokens(palavras,text)

#2º passo: retirando palavras desnecessárias no Excel

write_csv(pantanal_tokens,"pantanal_tokens.csv")

#3º passo: criando a nuvem

#Primeiro, faço o upload da base de palavras tratadas

pantanalcorpus <- Corpus(VectorSource(palavras_pantanal))

pantanalcorpus <- tm_map(pantanalcorpus, PlainTextDocument)

pantanalcorpus <- tm_map(pantanalcorpus, stemDocument)

wordcloud(pantanalcorpus,max.words=250,colors=c("blue","red"))

pantanalcorpus <- tm_map(pantanalcorpus, removePunctuation) 
